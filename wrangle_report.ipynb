{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRANGLE REPORT FOR WERATEDOGS\n",
    "\n",
    "This report contains my wrangling efforts for the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. \n",
    "I divided the wrangling into three parts; gathering, assessing and cleaning.\n",
    "\n",
    "### Gathering\n",
    "   I made use of the workspace provided by Udacity which is a jupyter notebook assessed through the course. I started by importing the libraries which I made use of during the course of the project such as pandas, numpy, requests, tweepy and others. I had to work with three datasets.\n",
    "The first dataset was twitter_archive_enhanced.csv, a comma separated variable file which was already made available on the workspace.\n",
    "The second dataset was image_predictions.tsv, a tab separated variable file which I had to query Udacity servers for and download programmatically using the requests library.\n",
    "The third dataset was an additional data I had to query twitter API for by applying for a twitter developer account and make use of a library named tweepy to download this data programmatically and save as tweet_json.txt.\n",
    "After gathering these datasets, I read the datasets into respective pandas dataframes using the pd.DataFrame(file) format.\n",
    "\n",
    "### Assessing\n",
    "I assessed the datasets both visually and (primarily) programmatically.\n",
    "Visual assessment: I displayed the datasets and scrolled to get familiar with the columns and sight any quality/tidiness issue. I also made use of the .sample() function to visually assess random samples from the datasets.\n",
    "Programmatic assessment: I made use of various pandas functions  such as .info(), .isnull(), .isnotnull(), .unique(), .nunique(), .duplicated(), .where() and others to assess the datasets.\n",
    "    At the end of the assessment I was able to point out 8 quality issues and 2 tidiness issues. These are:\n",
    "#### Quality issues\n",
    "df_archive_tweets\n",
    "1. table contained retweeted tweets \n",
    "\n",
    "2. retweeted_status_id, retweeted_status_user_id and retweeted_status_timestamp are not useful and should be dropped        \n",
    " \n",
    "3. some decimal ratings have been incorrectly extracted\n",
    "\n",
    "4. some ratings are not correct\n",
    "\n",
    "5. some ratings are inconsistent\n",
    "\n",
    "6. timestamp should be a datetime object\n",
    "\n",
    "7. some tweets do not contain ratings \n",
    "\n",
    "8. some rows have rating numerator as 0\n",
    "\n",
    "#### Tidiness issues\n",
    "1. doggo, floofer, pupper and puppo have been separated into different columns \n",
    "\n",
    "2. all 3 datasets should be merged into one master dataset and all duplicate columns be dropped\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "I cleaned the datasets by tackling the quality and tidiness issues already mentioned.\n",
    "\n",
    "- I made copies of the datasets before carrying out cleaning operations\n",
    "- I dropped rows with unclean data(incomplete, invalid or not useful)\n",
    "- I dropped off the columns that weren't useful\n",
    "- I reextracted the ratings to account for decimal ratings also\n",
    "- I cleaned the rating columns of incorrect, inconsistent and missing values\n",
    "- I reassigned correct datatypes to columns with wrong datatypes\n",
    "- I merged the doggo, floofer, pupper and puppo columns into a single column(stages) using the pandas.melt function\n",
    "- I merged all three clean datasets into a single master dataset named \"twitter_archive_master\" and saved it in a file named \"twitter_archive_master.csv\"\n",
    "\n",
    "At the end of the cleaning stage, my dataset was clean and ready for EDA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
